= Experiences of Test Automation: Ch17 Choosing The Wrong Tool =
Jeremy Kao <imsardine@gmail.com>
v1.0, 06 Feb. 2013
:data-uri:
:icons:

== Background ==

'A story about one person in the United States attempting to use a commercial tool.'

 * Period - Feb. 2009 - Oct.
 * Autohor - Michael Williamson
   ** a hard-core programmer
   ** software engineer in test, new to testing and test automation.
 * SUT - Webmaster Tools, Google
 * Tool - eggPlant (inherited), a dominant tool within Google.

== Situation ==

 * At a crossroad - the UI had just gone through a major overhaul, automation no longer worked.
 * Taking over the use of an existing tool, seemed sensible? because the tool had been so heavily used before...
 * That he later realized was 'not suitable' for what he was trying to test.
 * A lot of problems, particularly in automated comparison.
 * It was difficult to abandon something you have put a lot of effort into already.

== Testing ==

 * Follow the scripts and walk through the UI in every major browser.
 * L10N testing (23 languages)
 * End-to-end functional tests that try to simulate the interaction of a real user with a real web browser.

== Unacceptable Situation ==

 * Webmaster Tools still carried out most of its QA processes manually, even through Google was and is a very advanced company.
 * 3 weeks of development time, followed by 2 to 3 weeks of QA time (relatively large amount of time)

== Problem: Image-based Comparison ==

 * Extremely attractive -> tools features that look great when you first see them may not be so good when you try to use them in earnest.
 * This was its biggest selling point, it also turned out to be its largest drawback.
 * Browser rendering difference -> tweaking image tolerance (usually change from search to search)

== Problem: SenseTalk ==

 * Tests are written in SenseTalk (like English sentences), for someone who does not think like a software engineer.
 * None can help to review. a review is still an effective way to reduce bugs.

== Reluctance ==

New tool or major maintenance effort?

We periodically discussed the value of eggPlant during that 6-month period, but we didn't elect to throw everything out and start over with a new tool until the very end. Even through we knew that eggPlant had significant drawbacks early on, we were reluctant to give up all the work that we had spent so much time on. It eventually turned into a 'vicious cycle'. We didn't want to throw out all our hard work, which lead us to wasting more time writing unstable code, which we eventually had to throw out anyway.

== Bad automation is worse than no automation ==

but he didn't rely on them. he retested everything by hand, including the features that were already covered by the tests.

It was no fault of the team for using eggPlant during this period because there was nothing for browser automation that was any better.

== Lessons ==

 * It wasn't that eggPlant was a bad tool; it was just that we used it in the wrong environment.
 * Image (bitmap) comparisons are inefficient at best and are better avoided if possible.
 * Depending on how test automation is structured, vast amounts of effort may be thrown away when major changes occur to the system under test (SUT).
 * When you are spending too much time on maintenance of the automated test, it's time for significant changes, even if it means abandoning something you have put a lot of effort into.

